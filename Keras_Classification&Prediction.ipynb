{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import 分類用模型\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類測試用的數據\n",
    "# 生成一個二分類問題的數據集\n",
    "# n_samples 總數量；n_features：X一組內的資料數量；centers：數據的中間值(Y會根據這個產生int\n",
    "X, y = make_blobs(n_samples=100, n_features=2, centers=2, random_state=1)\n",
    "# n_samples是待生成的樣本的總數、n_features是每個樣本的特徵數、 centers表示類別數\n",
    "scalar = MinMaxScaler()  #標準化數據-1~1\n",
    "scalar.fit(X)\n",
    "X = scalar.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eac3b92940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義並擬合模型\n",
    "\n",
    "model = Sequential() #\n",
    "\n",
    "# 第一層要設定 輸入的物件的要求，範例為2D的矩陣X\n",
    "# Dense 全連接層，activation 激勵函數，4是指定輸出的空間維度(只能是正整數)\n",
    "model.add(Dense(4, input_dim=2, activation='relu')) # relu 整流線性單元\n",
    "\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='hard_sigmoid'))\n",
    "\n",
    "# 配置學習過程 (損失函數、優化契)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 訓練起來  (epochs = 網絡更新數\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.89337759 0.65864154], Predicted=[0]\n",
      "X=[0.29097707 0.12978982], Predicted=[1]\n",
      "X=[0.78082614 0.75391697], Predicted=[0]\n"
     ]
    }
   ],
   "source": [
    "Xnew, _ = make_blobs(n_samples=3, centers=2, n_features=2, random_state=1)\n",
    "Xnew = scalar.transform(Xnew)\n",
    "ynew = model.predict_classes(Xnew)\n",
    "\n",
    "for i in range(len(Xnew)):\n",
    "    print(\"X=%s, Predicted=%s\" % (Xnew[i], ynew[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "\n",
    "model.save(filepath)#将Keras模型和权重保存在一个HDF5\n",
    "keras.models.load_model(filepath) # 匯入模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在二分類問題下 預測可能分類為該類別的機率--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.89337759 0.65864154], Predicted=[0.00582727]\n",
      "X=[0.29097707 0.12978982], Predicted=[0.99573165]\n",
      "X=[0.78082614 0.75391697], Predicted=[0.00613513]\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X)\n",
    "X = scalar.transform(X)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "# sigmoid  這層作為輸出層，用於預測概率\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 編譯層\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# 新的未知數據\n",
    "Xnew, _ = make_blobs(n_samples=3, centers=2, n_features=2, random_state=1)\n",
    "Xnew = scalar.transform(Xnew)\n",
    "\n",
    "# 做预测\n",
    "ynew = model.predict_proba(Xnew)\n",
    "\n",
    "\n",
    "for i in range(len(Xnew)):\n",
    "    print(\"X=%s, Predicted=%s\" % (Xnew[i], ynew[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回歸預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 製作隨機數據\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1, random_state=1)\n",
    "\n",
    "scalarX, scalarY = MinMaxScaler(), MinMaxScaler()\n",
    "scalarX.fit(X)\n",
    "scalarY.fit(y.reshape(100,1))\n",
    "X = scalarX.transform(X)\n",
    "y = scalarY.transform(y.reshape(100,1))\n",
    "\n",
    "# 定義並擬合模型\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# 未知的新數據\n",
    "Xnew, a = make_regression(n_samples=3, n_features=2, noise=0.1, random_state=1)\n",
    "\n",
    "Xnew = scalarX.transform(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy\n",
    "import pandas\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu')) \n",
    "    model.add(Dense(8, init='uniform', activation='relu')) \n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "# dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(y=Y, n_folds=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到最適合神經網絡的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy\n",
    "import pandas\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init=init, activation='relu')) \n",
    "    model.add(Dense(8, init=init, activation='relu')) \n",
    "    model.add(Dense(1, init=init, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([50, 100, 150])\n",
    "batches = numpy.array([5, 10, 20])\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches,\n",
    "                  init=init) \n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類別變數設定\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實例測試 iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split , KFold,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "df = pd.read_csv(r'D:\\AYA\\test_file\\iris.csv')\n",
    "X = df[list(df)[0:4]].values.astype(float)\n",
    "Y = df[list(df)[-1]].values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)# one hot encoded\n",
    "\n",
    "# 把Y轉成1,0,0  0,1,0  這類的one hot encoded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設計大綱\n",
    "# 4個神經元 輸入層 -> [4個神經元 隱層] -> 3個神經元 輸出層\n",
    "# 因為有三種類的花\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # 數據用整流函數 所以激勵用relu\n",
    "    model.add(Dense(4, input_dim=4, init='normal', activation='relu')) \n",
    "\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    # 優化算法選擇ADAM隨機梯度下降，損失函數是對數函數\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "# verbose =0 是為了關閉調適訊息\n",
    "estimator = KerasClassifier(build_fn=baseline_model, nb_epoch=200,\n",
    "                            batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 31.33% (9.91%)\n"
     ]
    }
   ],
   "source": [
    "# K-Fold交叉檢驗\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 波士頓房屋為例 簡單的神經網絡 做回歸預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection  import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston['data']\n",
    "Y = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -114.95 (83.24) MSE\n"
     ]
    }
   ],
   "source": [
    "'''有一個全連接層，神經元數量和輸入變量數一致，激活函數還是整流函數。輸出層沒有激活\n",
    "函數，因為在回歸問題中我們希望直接取結果。優化函數是Adam，損失函數是MSE，和我們\n",
    "要優化的函數一致'''\n",
    "# MSE越小，說明模型的擬合實驗數據能力強\n",
    "\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    # 全连接层，因為X每筆是13個變數，所以全連階層這邊要設定一樣\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer=\"normal\", activation='relu')) \n",
    "    model.add(Dense(1, kernel_initializer=\"normal\"))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "    return model\n",
    "\n",
    "# 使用KerasRegressor封裝這個模型，任何其他的變量都會傳入fit()函數中，例如\n",
    "# 訓練次數和批次大小，這裡我們取默認值。為了可以復現結果，指定隨機數種子\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "\n",
    "# 10折測試\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -567.25 (277.43) MSE\n"
     ]
    }
   ],
   "source": [
    "'''預處理數據以增加性能，\n",
    "這個數據集的特點是變量的尺度不一致，所以標準化很有用。 scikit-learn的Pipeline可以\n",
    "直接進行均一化處理並交叉檢驗，這樣模型不會預先知道新的數據。代碼如下：'''\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', \n",
    "                   KerasRegressor(build_fn=baseline_model,\n",
    "                                  nb_epoch=50,\n",
    "                                  batch_size=5,\n",
    "                                  verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -571.95 (283.38) MSE\n"
     ]
    }
   ],
   "source": [
    "# 增加神经网络的层数可以提高效果，这样模型可以提取并组合更多的特征。\n",
    "\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu')) \n",
    "    #多這層\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu')) \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "    return model\n",
    "\n",
    "# 測試並正則化數據\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, nb_epoch=50, batch_size=5,\n",
    "    verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -560.86 (273.34) MSE\n"
     ]
    }
   ],
   "source": [
    "# 加寬模型可以增加網絡容量。我們減去一層，把隱層的神經元數量加大，從13加到20：\n",
    "\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu')) \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "    return model\n",
    "\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, nb_epoch=100, batch_size=5,\n",
    "    verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1ead447fef0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGR= larger_model()\n",
    "REGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用validation_split參數可以指定驗證數據的比例，一般是總數據的20%或者33%\n",
    "history = REGR.fit(X,Y, validation_split=0.33, epochs=40, batch_size=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
